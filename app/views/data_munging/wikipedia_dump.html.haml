%header
	%h1 Wikipedia Dumps
%section
	%h2 Beschreibung : Wikipeda Dumps
	%article
		%h3 Allgemein
		%p
			Wikipedia-Dump bezeichnet das Datenformat in dem man komplette Wikimedia-Projekte, wie z.B. die bekannte Online Enzyklopädie
			=link_to 'Wikipedia' ,'www.wikipedia.com', :rel=>'nofollow'
			herunterladen kann. Es ahndelt sich um XML-Dokumente in denen die Daten in der wikieignen Markupsprache kodiert sind.
		%p
			Die Dumps findet man unter
			=link_to 'Wiki Dumps', "http://dumps.wikimedia.org/backup-index.html", :rel => 'nofollow'
			\.
		
%section
	%h2 Struktur
	%article
		%h3 Formatierung
		keine in der Datei, in den Daten durch Wiki Markup
		%h3 Layout / Typen
		keine im XML, einige im WIki Markup
		%h3 Logische Strukturierung
		Zwei Ebenen:
		%ol
			%li Strukturiert: durch XML-Tags
			%li Semistrukturiert: Innerhalb von bestimmten XML Tags im Texteil in Wiki-Markup kodiert. Was und wie kodiert wird hängt vom Wikiprojekt ab.
%section
	%h2 Besonderheiten
	%article
		%h3 Wiki-Markup
		%p Wiki markaup bzw. wikitext bezeichnet eine nicht standartisierte Auszeichnungssprache, welche ein vereinfachtes Subset von HTML zur Verfügung stellt. Es weren keine Tags sondern spezielle Zeichenkombination benutzt um diese Elemete zu kodieren
		%h3 Überblick über die in Wikimarkup verwendeten Tags
		=link_to 'Mehr zu Wiki markup', 'http://en.wikipedia.org/wiki/Help:Wiki_markup', :rel=>'nofollow'
%sevtion
	%h2 Beispiele
	%article
		%h3 Wiki-Dump-XML: Auszug
		%p Auszug aus einem Dump des Wiktionairy.
		~sanitize highlight @wiki_dump_example, :xml
		%h3 Wiki-Markup: Auszug
		%p Beispiel für wiki markup.
		%p
			Originalartikel:
			=link_to 'Artikel zu "ordo"','http://de.wiktionary.org/wiki/ordo', :rel => 'nofollow'
		~sanitize highlight @wiki_markup_example, :markup
%section
	%header
		%h2 Wikipedia Dumps anzeigen und bearbeiten
	%article
		%h3 Anzeigen
		%p Aufgrund der Dateigrößen kann man sich die Dumps nur AUszugweiße in normalen Browsern/XML-Editoren betrachten.
		%h3 Bearbeiten
		%p Die Dumps werden im normalfall programmatisch bearbeitet. Die Bearbeitung muss in zwei Schritten erfolgen:
		%ol
			%li XML parsen (hier nur effektiv mit SAX bzw. Pull-Parser möglich), gewünschte Information extrahieren
			%li 
				Wiki markup parsen: 
				%ol
					%li Für grobe Extraktion z.B. mit regulären Ausdrücken
					%li mit einem speziellen Parser für wiki markup
%section
	%header
		%h2 Tools um mit Wikipedia-Dumps zu arbeiten
	%article 
		%p Danke an David Kaumans und Max Hadersbeck für dieses Softwarepaket.
		%p=link_to 'Software-Paket mit Skripten zum extrahieren von Wikidaten', '/data/data_munging/WikiExtractor.zip'
		%p
			%pre
				Aus Dump extrahieren:
				bzip2 -dc .dewiktionary-latest-pages-articles.xml.bz2 | python
				WikiExtractor.py -o extracted

				Wiki-Markup strippen (entsprechende Unterordner aus extracted/ einfach
				dazuschreiben):
				for dir in {'AA','AB','AC','AD','AE','AF','AG','AH','AI'}; do mkdir
				\./stripped/$dir; for i in {00..99}; do bzip2 -cdv
				\./extracted/$dir/wiki$i.bz2 | html2text -utf8 > ./stripped/$dir/wiki$i.txt;
				done; done; echo "Done.";

				Säubern, Normalisieren:
				for dir in ./stripped/*; do for file in $dir/*.txt; do echo "Cleaning
				$file..."; cat $file | tr "_" " " > tmp; mv tmp $file; done; done; echo
				"Done.";


= render :partial => "shared/examples"

	
		
